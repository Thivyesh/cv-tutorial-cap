{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real-time Object Detection with YOLO and OpenCV\n",
    "\n",
    "## Overview:\n",
    "\n",
    "This script demonstrates real-time object detection using the You Only Look Once (YOLO) model, DEtection TRansformers (DETR) model and OpenCV. YOLO is a popular deep learning-based object detection algorithm that is known for its speed and accuracy. DETR is an object detection model that directly predicts object bounding boxes and class labels using transformer-based encoder-decoder architecture. OpenCV is a powerful library used for computer vision tasks, including image processing and object detection.\n",
    "\n",
    "## Concepts:\n",
    "\n",
    "### YOLO (You Only Look Once):\n",
    "   - YOLO is a real-time object detection algorithm that detects objects in images or video frames.\n",
    "   - It divides the input image into a grid and predicts bounding boxes and class probabilities for each grid cell simultaneously.\n",
    "   - YOLO can detect multiple objects in a single pass through the neural network, making it extremely fast.\n",
    "\n",
    "### OpenCV:\n",
    "   - OpenCV (Open Source Computer Vision Library) is an open-source computer vision and machine learning software library.\n",
    "   - It provides a wide range of tools and algorithms for image and video processing tasks.\n",
    "   - OpenCV is widely used for tasks such as object detection, facial recognition, and image segmentation.\n",
    "\n",
    "## Code Explanation:\n",
    "\n",
    "### Importing Libraries:\n",
    "  - The script imports necessary libraries including `cv2` for OpenCV, `YOLO` from `ultralytics` for object detection, and `supervision` for annotations.\n",
    "\n",
    "### Initializing YOLO Model:\n",
    "  - The YOLO model is initialized using pre-trained weights (`yolov8s.pt`). These weights are obtained from training on a large dataset and are used to perform object detection.\n",
    "\n",
    "### Initializing Webcam Capture:\n",
    "  - The script initializes webcam capture using OpenCV's `VideoCapture` class. If the webcam cannot be opened, an error message is printed and the script exits.\n",
    "\n",
    "### Real-time Object Detection Loop:\n",
    "  - The script enters a while loop to continuously capture frames from the webcam and perform object detection on each frame.\n",
    "  - Each frame captured from the webcam is passed through the YOLO model to detect objects.\n",
    "  - Detected objects are annotated with bounding boxes and labels using the `supervision` library.\n",
    "  - Annotated frames are displayed in real-time using OpenCV's `imshow` function.\n",
    "  - The loop continues until the user presses the 'q' key, at which point the webcam is released and OpenCV windows are closed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Object Detection:\n",
    "   - Object detection is a computer vision task that involves detecting and locating objects within an image or video frame.\n",
    "   - It differs from image classification, which identifies the main object in an entire image, by providing the precise location of each object along with its class label.\n",
    "   - Object detection algorithms typically use machine learning techniques, such as deep neural networks, to perform this task.\n",
    "\n",
    "### Real-time Object Detection vs Batch Object Detection:\n",
    "   - Real-time object detection refers to the ability to perform object detection on live video streams in real-time, usually at frame rates of at least 30 frames per second (FPS).\n",
    "   - Batch object detection, on the other hand, involves processing a batch of images or video frames offline, without the constraint of real-time processing.\n",
    "   - Real-time object detection is often used in applications such as video surveillance, autonomous driving, and augmented reality, where timely detection of objects is critical.\n",
    "\n",
    "### YOLOv8 Architecture:\n",
    "   - YOLOv8 (You Only Look Once version 8) is an improvement over previous versions of the YOLO algorithm, known for its efficiency and accuracy in object detection tasks.\n",
    "   - YOLOv8 is based on a deep convolutional neural network architecture that divides the input image into a grid of cells and predicts bounding boxes and class probabilities for each cell simultaneously.\n",
    "   - It uses a single neural network to predict multiple bounding boxes and class probabilities for each object in the image, making it extremely fast and efficient.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries:\n",
    "  - The script imports necessary libraries including `cv2` for OpenCV, `torch` for object detection, and `supervision` for annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import supervision as sv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing YOLO Model:\n",
    "  - The YOLO model is initialized using pre-trained weights (`yolov5s.pt`). These weights are obtained from training on a large dataset and are used to perform object detection.\n",
    "\n",
    "### Initializing Webcam Capture:\n",
    "  - The script initializes webcam capture using OpenCV's `VideoCapture` class. If the webcam cannot be opened, an error message is printed and the script exits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize yolo model\n",
    "model = torch.hub.load(\"ultralytics/yolov5\", \"yolov5s\", pretrained=True)\n",
    "#Initialize webcam capture\n",
    "cap = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real-time Object Detection Loop:\n",
    "  - The script enters a while loop to continuously capture frames from the webcam and perform object detection on each frame.\n",
    "  - A video is a sequence of frames (images)\n",
    "  - Each frame captured from the webcam is passed through the YOLO model to detect objects.\n",
    "  - Detected objects are annotated with bounding boxes and labels using the `supervision` library.\n",
    "  - Annotated frames are displayed in real-time using OpenCV's `imshow` function.\n",
    "  - The loop continues until the user presses the 'q' key, at which point the webcam is released and OpenCV windows are closed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 5 persons, 1 chair, 66.8ms\n",
      "Speed: 1.6ms preprocess, 66.8ms inference, 323.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 1 chair, 76.2ms\n",
      "Speed: 1.1ms preprocess, 76.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 chair, 80.8ms\n",
      "Speed: 1.2ms preprocess, 80.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 chair, 77.1ms\n",
      "Speed: 1.5ms preprocess, 77.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 chair, 57.6ms\n",
      "Speed: 1.1ms preprocess, 57.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 chair, 54.1ms\n",
      "Speed: 1.1ms preprocess, 54.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 chair, 53.6ms\n",
      "Speed: 1.1ms preprocess, 53.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 chair, 60.1ms\n",
      "Speed: 1.3ms preprocess, 60.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 chair, 52.1ms\n",
      "Speed: 1.0ms preprocess, 52.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 chair, 56.3ms\n",
      "Speed: 1.2ms preprocess, 56.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 chair, 60.6ms\n",
      "Speed: 1.0ms preprocess, 60.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 chair, 58.2ms\n",
      "Speed: 1.2ms preprocess, 58.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 chair, 62.4ms\n",
      "Speed: 1.3ms preprocess, 62.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 chair, 59.0ms\n",
      "Speed: 1.1ms preprocess, 59.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 chair, 66.5ms\n",
      "Speed: 1.3ms preprocess, 66.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 chair, 57.3ms\n",
      "Speed: 1.3ms preprocess, 57.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 chair, 53.4ms\n",
      "Speed: 1.2ms preprocess, 53.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 chair, 61.7ms\n",
      "Speed: 1.1ms preprocess, 61.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 chair, 59.6ms\n",
      "Speed: 1.4ms preprocess, 59.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 chair, 56.7ms\n",
      "Speed: 1.3ms preprocess, 56.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 chair, 56.6ms\n",
      "Speed: 1.1ms preprocess, 56.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 chair, 60.6ms\n",
      "Speed: 1.1ms preprocess, 60.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 chair, 54.3ms\n",
      "Speed: 1.2ms preprocess, 54.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 chair, 58.4ms\n",
      "Speed: 1.3ms preprocess, 58.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 chair, 58.1ms\n",
      "Speed: 1.0ms preprocess, 58.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 chair, 54.2ms\n",
      "Speed: 1.1ms preprocess, 54.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 chair, 61.0ms\n",
      "Speed: 1.1ms preprocess, 61.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 chair, 1 cell phone, 57.4ms\n",
      "Speed: 1.3ms preprocess, 57.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 chair, 57.1ms\n",
      "Speed: 1.0ms preprocess, 57.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 chair, 60.0ms\n",
      "Speed: 1.0ms preprocess, 60.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 chair, 58.2ms\n",
      "Speed: 1.2ms preprocess, 58.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 chair, 55.9ms\n",
      "Speed: 1.4ms preprocess, 55.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 chair, 60.8ms\n",
      "Speed: 1.3ms preprocess, 60.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 chair, 54.8ms\n",
      "Speed: 1.0ms preprocess, 54.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 chair, 77.6ms\n",
      "Speed: 1.4ms preprocess, 77.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 chair, 65.3ms\n",
      "Speed: 1.1ms preprocess, 65.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 chair, 65.2ms\n",
      "Speed: 1.1ms preprocess, 65.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 chair, 62.0ms\n",
      "Speed: 1.2ms preprocess, 62.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 chair, 62.6ms\n",
      "Speed: 1.1ms preprocess, 62.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 chair, 69.4ms\n",
      "Speed: 1.3ms preprocess, 69.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 chair, 68.3ms\n",
      "Speed: 1.3ms preprocess, 68.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 chair, 62.0ms\n",
      "Speed: 1.3ms preprocess, 62.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 chair, 1 toothbrush, 56.6ms\n",
      "Speed: 1.1ms preprocess, 56.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 chair, 68.7ms\n",
      "Speed: 1.2ms preprocess, 68.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 chair, 66.3ms\n",
      "Speed: 1.3ms preprocess, 66.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 chair, 63.9ms\n",
      "Speed: 1.3ms preprocess, 63.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 chair, 67.4ms\n",
      "Speed: 1.0ms preprocess, 67.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "#cap.isOpened checks if the camera is connected and can capture(open)\n",
    "if not cap.isOpened():\n",
    "    print(\"Cannot open camera\")\n",
    "    exit()\n",
    "while True:\n",
    "    #ret is boolean which is True if the camera stream can be read\n",
    "    #frame is the picture captured during streaming\n",
    "    ret, frame =  cap.read()\n",
    "\n",
    "    #If ret is equal to False the loop will break\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?), Exiting ...\")\n",
    "        break\n",
    "    \n",
    "    #predict with the model\n",
    "    results = model(frame)\n",
    "\n",
    "    #pass the results to the supervision class to process results\n",
    "    #Show example of results\n",
    "    detections = sv.Detections.from_yolov5(results)\n",
    "\n",
    "    #Define the annotator that will draw the boundingboxes on the image\n",
    "    bounding_box_annotator = sv.BoundingBoxAnnotator(\n",
    "        thickness=4\n",
    "    )\n",
    "\n",
    "    #Define the label annotator which will add label to the annotations\n",
    "    label_annotator = sv.LabelAnnotator()\n",
    "\n",
    "    # Remove human class\n",
    "    # detections = detections[detections.class_id !=0]\n",
    "\n",
    "    #Extract the labels from the model object to pass into the label annotator\n",
    "    #The labels will be in a dict format:\n",
    "    # {human: 0}\n",
    "    labels = [\n",
    "        model.model.names[class_id]\n",
    "        for class_id\n",
    "        in detections.class_id\n",
    "    ]\n",
    "\n",
    "    #Annotate (draw) the fram (image) with boundingboxes\n",
    "    # A bounding boxes is defined by coordinates like for example:\n",
    "    # x1, x2, y1, y2\n",
    "    # These are coordinates \n",
    "    annotated_image = bounding_box_annotator.annotate(\n",
    "        scene=frame, detections=detections)\n",
    "    \n",
    "    # Annotate each bounding box with its label\n",
    "    # Each bounding box will have an id which is linked to each cls (class) which is a int\n",
    "    # The int is used to lookup in the labels dict\n",
    "    annotated_image = label_annotator.annotate(\n",
    "        scene=annotated_image, detections=detections, labels=labels)\n",
    "\n",
    "    #Show the frame with opencv\n",
    "    # When pressing  q the popup window with the frame will close\n",
    "    cv2.imshow(\"frame\", annotated_image)\n",
    "    if cv2.waitKey(1) == ord(\"q\"):\n",
    "        break\n",
    "#disconnect from the camera\n",
    "cap.release()\n",
    "#Close all cv2 opened windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An example of how the code can be structured as a python class\n",
    "- In this class:\n",
    "  - **__init__**: Initializes the needed variables\n",
    "  - **__del__**: Is a function to disconnect from the camera and close all windows opened by cv2.\n",
    "  - **detect_objects**: Creates a loop where:\n",
    "    - It checks if the camera is connected, if not then disconnect\n",
    "    - predicts, and creates annotations with bounding boxes and labels\n",
    "    - Displays the result with cv2, where you close the opened window by pressing \"q\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 86.7ms\n",
      "Speed: 2.9ms preprocess, 86.7ms inference, 355.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 63.9ms\n",
      "Speed: 1.3ms preprocess, 63.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 83.4ms\n",
      "Speed: 1.7ms preprocess, 83.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 95.3ms\n",
      "Speed: 1.1ms preprocess, 95.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 57.5ms\n",
      "Speed: 1.3ms preprocess, 57.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 59.5ms\n",
      "Speed: 1.2ms preprocess, 59.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 56.3ms\n",
      "Speed: 1.2ms preprocess, 56.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 65.1ms\n",
      "Speed: 1.1ms preprocess, 65.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 63.9ms\n",
      "Speed: 1.3ms preprocess, 63.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 62.0ms\n",
      "Speed: 1.2ms preprocess, 62.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 60.0ms\n",
      "Speed: 1.2ms preprocess, 60.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 55.4ms\n",
      "Speed: 1.0ms preprocess, 55.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 59.6ms\n",
      "Speed: 1.2ms preprocess, 59.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 61.7ms\n",
      "Speed: 1.2ms preprocess, 61.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 umbrella, 57.7ms\n",
      "Speed: 1.4ms preprocess, 57.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 umbrella, 57.8ms\n",
      "Speed: 1.1ms preprocess, 57.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 66.3ms\n",
      "Speed: 1.3ms preprocess, 66.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 54.1ms\n",
      "Speed: 1.1ms preprocess, 54.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 59.3ms\n",
      "Speed: 1.5ms preprocess, 59.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 58.3ms\n",
      "Speed: 1.2ms preprocess, 58.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 60.5ms\n",
      "Speed: 1.4ms preprocess, 60.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 umbrella, 75.8ms\n",
      "Speed: 1.2ms preprocess, 75.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 59.4ms\n",
      "Speed: 1.4ms preprocess, 59.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 68.1ms\n",
      "Speed: 1.3ms preprocess, 68.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 59.8ms\n",
      "Speed: 1.3ms preprocess, 59.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 69.7ms\n",
      "Speed: 1.2ms preprocess, 69.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 60.4ms\n",
      "Speed: 1.4ms preprocess, 60.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 56.8ms\n",
      "Speed: 1.0ms preprocess, 56.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 67.7ms\n",
      "Speed: 1.6ms preprocess, 67.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 60.7ms\n",
      "Speed: 1.2ms preprocess, 60.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 57.7ms\n",
      "Speed: 1.4ms preprocess, 57.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 61.9ms\n",
      "Speed: 1.0ms preprocess, 61.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 54.7ms\n",
      "Speed: 1.4ms preprocess, 54.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 59.3ms\n",
      "Speed: 1.3ms preprocess, 59.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 57.2ms\n",
      "Speed: 1.1ms preprocess, 57.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 58.3ms\n",
      "Speed: 1.4ms preprocess, 58.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 62.3ms\n",
      "Speed: 1.5ms preprocess, 62.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 59.9ms\n",
      "Speed: 1.1ms preprocess, 59.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 62.9ms\n",
      "Speed: 1.2ms preprocess, 62.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 58.3ms\n",
      "Speed: 1.1ms preprocess, 58.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 umbrella, 64.4ms\n",
      "Speed: 1.3ms preprocess, 64.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 54.4ms\n",
      "Speed: 1.3ms preprocess, 54.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 umbrella, 61.7ms\n",
      "Speed: 1.2ms preprocess, 61.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 66.1ms\n",
      "Speed: 1.4ms preprocess, 66.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 umbrella, 59.8ms\n",
      "Speed: 1.4ms preprocess, 59.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 umbrella, 64.2ms\n",
      "Speed: 1.1ms preprocess, 64.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 umbrella, 62.2ms\n",
      "Speed: 1.4ms preprocess, 62.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 umbrella, 63.2ms\n",
      "Speed: 1.1ms preprocess, 63.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 71.2ms\n",
      "Speed: 1.2ms preprocess, 71.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 59.3ms\n",
      "Speed: 1.2ms preprocess, 59.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 umbrella, 61.8ms\n",
      "Speed: 1.2ms preprocess, 61.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 62.9ms\n",
      "Speed: 1.2ms preprocess, 62.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 59.7ms\n",
      "Speed: 1.3ms preprocess, 59.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 67.1ms\n",
      "Speed: 1.0ms preprocess, 67.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 57.2ms\n",
      "Speed: 1.1ms preprocess, 57.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 54.2ms\n",
      "Speed: 1.3ms preprocess, 54.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 56.3ms\n",
      "Speed: 1.4ms preprocess, 56.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 55.8ms\n",
      "Speed: 1.2ms preprocess, 55.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 60.0ms\n",
      "Speed: 1.4ms preprocess, 60.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 60.8ms\n",
      "Speed: 1.5ms preprocess, 60.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 58.4ms\n",
      "Speed: 1.4ms preprocess, 58.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 64.7ms\n",
      "Speed: 1.2ms preprocess, 64.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 60.0ms\n",
      "Speed: 1.2ms preprocess, 60.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 55.7ms\n",
      "Speed: 1.0ms preprocess, 55.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 60.4ms\n",
      "Speed: 1.3ms preprocess, 60.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 63.0ms\n",
      "Speed: 1.3ms preprocess, 63.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 63.3ms\n",
      "Speed: 1.2ms preprocess, 63.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 55.9ms\n",
      "Speed: 1.0ms preprocess, 55.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 58.0ms\n",
      "Speed: 1.4ms preprocess, 58.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 58.8ms\n",
      "Speed: 1.4ms preprocess, 58.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 67.0ms\n",
      "Speed: 1.4ms preprocess, 67.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 64.5ms\n",
      "Speed: 1.1ms preprocess, 64.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 56.9ms\n",
      "Speed: 1.2ms preprocess, 56.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 62.4ms\n",
      "Speed: 1.1ms preprocess, 62.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 66.3ms\n",
      "Speed: 1.5ms preprocess, 66.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 64.4ms\n",
      "Speed: 1.1ms preprocess, 64.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 60.6ms\n",
      "Speed: 1.2ms preprocess, 60.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 70.5ms\n",
      "Speed: 1.0ms preprocess, 70.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 64.8ms\n",
      "Speed: 1.4ms preprocess, 64.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 61.2ms\n",
      "Speed: 1.1ms preprocess, 61.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 56.2ms\n",
      "Speed: 1.3ms preprocess, 56.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 63.1ms\n",
      "Speed: 1.4ms preprocess, 63.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 67.0ms\n",
      "Speed: 1.1ms preprocess, 67.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 67.6ms\n",
      "Speed: 1.4ms preprocess, 67.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 72.1ms\n",
      "Speed: 1.2ms preprocess, 72.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 55.2ms\n",
      "Speed: 1.3ms preprocess, 55.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 58.5ms\n",
      "Speed: 1.2ms preprocess, 58.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 55.7ms\n",
      "Speed: 1.4ms preprocess, 55.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 73.2ms\n",
      "Speed: 1.2ms preprocess, 73.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 56.4ms\n",
      "Speed: 1.0ms preprocess, 56.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 65.3ms\n",
      "Speed: 1.4ms preprocess, 65.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 59.9ms\n",
      "Speed: 1.3ms preprocess, 59.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 62.6ms\n",
      "Speed: 1.4ms preprocess, 62.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 66.9ms\n",
      "Speed: 1.3ms preprocess, 66.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 54.4ms\n",
      "Speed: 1.3ms preprocess, 54.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 58.8ms\n",
      "Speed: 1.4ms preprocess, 58.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 62.6ms\n",
      "Speed: 1.5ms preprocess, 62.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 75.6ms\n",
      "Speed: 1.1ms preprocess, 75.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 70.8ms\n",
      "Speed: 1.5ms preprocess, 70.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 66.2ms\n",
      "Speed: 1.2ms preprocess, 66.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 64.0ms\n",
      "Speed: 1.5ms preprocess, 64.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 58.4ms\n",
      "Speed: 1.1ms preprocess, 58.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 66.7ms\n",
      "Speed: 1.2ms preprocess, 66.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 65.3ms\n",
      "Speed: 1.2ms preprocess, 65.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 58.4ms\n",
      "Speed: 1.4ms preprocess, 58.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 65.1ms\n",
      "Speed: 1.1ms preprocess, 65.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 64.4ms\n",
      "Speed: 1.2ms preprocess, 64.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 67.8ms\n",
      "Speed: 1.1ms preprocess, 67.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 58.4ms\n",
      "Speed: 1.4ms preprocess, 58.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 wine glass, 1 toothbrush, 57.9ms\n",
      "Speed: 1.2ms preprocess, 57.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 57.7ms\n",
      "Speed: 1.5ms preprocess, 57.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 59.0ms\n",
      "Speed: 1.2ms preprocess, 59.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 63.4ms\n",
      "Speed: 1.3ms preprocess, 63.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 63.4ms\n",
      "Speed: 1.4ms preprocess, 63.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 67.5ms\n",
      "Speed: 1.2ms preprocess, 67.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 80.7ms\n",
      "Speed: 1.2ms preprocess, 80.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 53.6ms\n",
      "Speed: 1.1ms preprocess, 53.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 53.4ms\n",
      "Speed: 1.5ms preprocess, 53.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 63.4ms\n",
      "Speed: 1.1ms preprocess, 63.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 53.2ms\n",
      "Speed: 1.5ms preprocess, 53.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 55.2ms\n",
      "Speed: 1.1ms preprocess, 55.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 53.0ms\n",
      "Speed: 1.1ms preprocess, 53.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 suitcase, 61.2ms\n",
      "Speed: 1.1ms preprocess, 61.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 59.6ms\n",
      "Speed: 1.1ms preprocess, 59.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 53.7ms\n",
      "Speed: 1.5ms preprocess, 53.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 62.5ms\n",
      "Speed: 1.4ms preprocess, 62.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 suitcase, 62.2ms\n",
      "Speed: 1.1ms preprocess, 62.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 suitcase, 52.9ms\n",
      "Speed: 1.1ms preprocess, 52.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 suitcase, 1 refrigerator, 59.0ms\n",
      "Speed: 1.3ms preprocess, 59.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 handbag, 1 suitcase, 1 refrigerator, 60.5ms\n",
      "Speed: 1.2ms preprocess, 60.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 62.2ms\n",
      "Speed: 1.1ms preprocess, 62.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cup, 53.8ms\n",
      "Speed: 1.1ms preprocess, 53.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cup, 1 refrigerator, 55.2ms\n",
      "Speed: 1.1ms preprocess, 55.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 3 wine glasss, 53.5ms\n",
      "Speed: 1.5ms preprocess, 53.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 wine glass, 59.4ms\n",
      "Speed: 1.3ms preprocess, 59.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 refrigerator, 60.2ms\n",
      "Speed: 1.2ms preprocess, 60.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 67.4ms\n",
      "Speed: 1.3ms preprocess, 67.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 refrigerators, 61.5ms\n",
      "Speed: 1.1ms preprocess, 61.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cup, 1 bowl, 1 refrigerator, 59.7ms\n",
      "Speed: 1.1ms preprocess, 59.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 chair, 1 refrigerator, 52.6ms\n",
      "Speed: 1.2ms preprocess, 52.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 chairs, 1 refrigerator, 55.1ms\n",
      "Speed: 1.1ms preprocess, 55.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 refrigerator, 57.5ms\n",
      "Speed: 1.3ms preprocess, 57.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 refrigerator, 65.8ms\n",
      "Speed: 1.0ms preprocess, 65.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 refrigerator, 58.5ms\n",
      "Speed: 1.5ms preprocess, 58.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 refrigerator, 53.9ms\n",
      "Speed: 1.5ms preprocess, 53.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 refrigerator, 53.6ms\n",
      "Speed: 1.5ms preprocess, 53.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bowl, 1 refrigerator, 60.6ms\n",
      "Speed: 1.0ms preprocess, 60.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 refrigerator, 70.9ms\n",
      "Speed: 1.1ms preprocess, 70.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 1 bowl, 1 refrigerator, 52.9ms\n",
      "Speed: 1.1ms preprocess, 52.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 refrigerator, 56.6ms\n",
      "Speed: 1.4ms preprocess, 56.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 refrigerator, 59.2ms\n",
      "Speed: 1.3ms preprocess, 59.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 refrigerator, 54.9ms\n",
      "Speed: 1.0ms preprocess, 54.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 refrigerator, 75.1ms\n",
      "Speed: 1.2ms preprocess, 75.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 refrigerator, 58.2ms\n",
      "Speed: 1.1ms preprocess, 58.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 refrigerator, 60.5ms\n",
      "Speed: 1.1ms preprocess, 60.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 refrigerator, 65.1ms\n",
      "Speed: 1.5ms preprocess, 65.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 refrigerator, 62.8ms\n",
      "Speed: 1.5ms preprocess, 62.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 refrigerator, 63.9ms\n",
      "Speed: 1.1ms preprocess, 63.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 refrigerator, 67.8ms\n",
      "Speed: 1.1ms preprocess, 67.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 wine glass, 62.5ms\n",
      "Speed: 1.3ms preprocess, 62.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 refrigerator, 53.9ms\n",
      "Speed: 1.3ms preprocess, 53.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 54.4ms\n",
      "Speed: 1.5ms preprocess, 54.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 65.5ms\n",
      "Speed: 1.1ms preprocess, 65.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 suitcase, 61.9ms\n",
      "Speed: 1.3ms preprocess, 61.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 51.7ms\n",
      "Speed: 1.2ms preprocess, 51.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 suitcase, 65.0ms\n",
      "Speed: 1.5ms preprocess, 65.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 suitcase, 1 refrigerator, 67.2ms\n",
      "Speed: 1.0ms preprocess, 67.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 suitcase, 63.5ms\n",
      "Speed: 1.4ms preprocess, 63.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 suitcase, 67.7ms\n",
      "Speed: 1.1ms preprocess, 67.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 suitcase, 54.1ms\n",
      "Speed: 1.1ms preprocess, 54.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 suitcase, 62.3ms\n",
      "Speed: 1.1ms preprocess, 62.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 suitcase, 1 refrigerator, 63.0ms\n",
      "Speed: 1.5ms preprocess, 63.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 suitcase, 64.2ms\n",
      "Speed: 1.1ms preprocess, 64.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 suitcase, 2 refrigerators, 65.8ms\n",
      "Speed: 1.1ms preprocess, 65.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 56.9ms\n",
      "Speed: 1.3ms preprocess, 56.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 61.5ms\n",
      "Speed: 1.4ms preprocess, 61.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 60.5ms\n",
      "Speed: 1.1ms preprocess, 60.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bed, 56.4ms\n",
      "Speed: 1.1ms preprocess, 56.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 refrigerator, 55.6ms\n",
      "Speed: 1.4ms preprocess, 55.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 refrigerator, 55.5ms\n",
      "Speed: 1.2ms preprocess, 55.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 refrigerator, 55.6ms\n",
      "Speed: 1.2ms preprocess, 55.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bed, 54.5ms\n",
      "Speed: 1.1ms preprocess, 54.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 64.3ms\n",
      "Speed: 1.1ms preprocess, 64.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 60.5ms\n",
      "Speed: 1.1ms preprocess, 60.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 55.5ms\n",
      "Speed: 1.2ms preprocess, 55.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 59.3ms\n",
      "Speed: 1.1ms preprocess, 59.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 52.9ms\n",
      "Speed: 1.4ms preprocess, 52.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 refrigerator, 63.3ms\n",
      "Speed: 1.6ms preprocess, 63.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 refrigerator, 54.0ms\n",
      "Speed: 1.3ms preprocess, 54.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 64.8ms\n",
      "Speed: 1.1ms preprocess, 64.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 refrigerator, 64.7ms\n",
      "Speed: 1.1ms preprocess, 64.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 refrigerator, 57.0ms\n",
      "Speed: 1.5ms preprocess, 57.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 refrigerator, 57.1ms\n",
      "Speed: 1.5ms preprocess, 57.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cup, 65.2ms\n",
      "Speed: 1.4ms preprocess, 65.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bed, 1 refrigerator, 67.4ms\n",
      "Speed: 1.1ms preprocess, 67.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 refrigerator, 56.9ms\n",
      "Speed: 1.1ms preprocess, 56.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 refrigerator, 56.8ms\n",
      "Speed: 1.2ms preprocess, 56.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 wine glasss, 1 refrigerator, 60.0ms\n",
      "Speed: 1.1ms preprocess, 60.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 refrigerator, 56.8ms\n",
      "Speed: 1.2ms preprocess, 56.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 refrigerator, 64.8ms\n",
      "Speed: 1.3ms preprocess, 64.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 66.1ms\n",
      "Speed: 1.4ms preprocess, 66.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 64.6ms\n",
      "Speed: 1.1ms preprocess, 64.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 54.6ms\n",
      "Speed: 1.1ms preprocess, 54.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cup, 1 refrigerator, 60.5ms\n",
      "Speed: 1.1ms preprocess, 60.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch  # Import YOLO model from Ultralytics\n",
    "import supervision as sv  # Import the supervision library for annotations\n",
    "\n",
    "class ObjectDetectionWithWebcam:\n",
    "    \"\"\"\n",
    "    This class performs real-time object detection using a webcam and YOLO model.\n",
    "\n",
    "    Attributes:\n",
    "        model (YOLO): YOLO object detection model.\n",
    "        webcam (cv2.VideoCapture): Webcam object for capturing frames.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model_weights: str = \"ultralytics/yolov5\", model_name: str = \"yolov5s\"):\n",
    "        \"\"\"\n",
    "        Initializes the ObjectDetectionWithWebcam class.\n",
    "\n",
    "        Args:\n",
    "            model_weights (str): Path to the YOLO model weights file (default is 'yolov8s.pt').\n",
    "        \"\"\"\n",
    "        self.model = torch.hub.load(model_weights, model_name, pretrained=True)\n",
    "\n",
    "        self.webcam = cv2.VideoCapture(0)\n",
    "\n",
    "        if not self.webcam.isOpened():\n",
    "            raise RuntimeError(\"Cannot open webcam\")\n",
    "\n",
    "    def __del__(self):\n",
    "        \"\"\"\n",
    "        Cleans up resources by releasing the webcam.\n",
    "        \"\"\"\n",
    "        self.webcam.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    def detect_objects(self):\n",
    "        \"\"\"\n",
    "        Performs real-time object detection using the webcam and displays the annotated frames.\n",
    "        \"\"\"\n",
    "        while True:\n",
    "            # Read frame from webcam\n",
    "            ret, frame = self.webcam.read()\n",
    "\n",
    "            if not ret:\n",
    "                print(\"Can't receive frame (stream end?), Exiting ...\")\n",
    "                break\n",
    "            \n",
    "            # Perform object detection on the frame using the YOLO model\n",
    "            results = self.model(frame)\n",
    "\n",
    "            # Convert YOLO detections to Supervision Detections format\n",
    "            detections = sv.Detections.from_yolov5(results)\n",
    "\n",
    "            # Create a bounding box annotator with specified thickness\n",
    "            bounding_box_annotator = sv.BoundingBoxAnnotator(\n",
    "                thickness=4\n",
    "            )\n",
    "\n",
    "            # Create a label annotator\n",
    "            label_annotator = sv.LabelAnnotator()\n",
    "\n",
    "            # Filter out detections with class_id not equal to 0 (human class)\n",
    "            # detections = detections[detections.class_id != 0] #optional\n",
    "\n",
    "            # Get labels for each detected object\n",
    "            labels = [\n",
    "                self.model.model.names[class_id]\n",
    "                for class_id\n",
    "                in detections.class_id\n",
    "            ]\n",
    "\n",
    "            # Annotate the frame with bounding boxes\n",
    "            annotated_image = bounding_box_annotator.annotate(\n",
    "                scene=frame, detections=detections)\n",
    "\n",
    "            # Annotate the frame with labels\n",
    "            annotated_image = label_annotator.annotate(\n",
    "                scene=annotated_image, detections=detections, labels=labels)\n",
    "\n",
    "            # Display the annotated frame\n",
    "            cv2.imshow(\"Object Detection\", annotated_image)\n",
    "\n",
    "            # Exit loop if 'q' key is pressed\n",
    "            if cv2.waitKey(1) == ord(\"q\"):\n",
    "                break\n",
    "\n",
    "# Usage example:\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize ObjectDetectionWithWebcam class\n",
    "    detector = ObjectDetectionWithWebcam()\n",
    "\n",
    "    # Perform real-time object detection\n",
    "    detector.detect_objects()\n",
    "    detector.__del__()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv-tutorial-cap-aU5aeIk7-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
