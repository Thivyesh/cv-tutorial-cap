{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 bed, 108.5ms\n",
      "Speed: 2.4ms preprocess, 108.5ms inference, 359.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 2 beds, 70.0ms\n",
      "Speed: 1.4ms preprocess, 70.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bed, 89.4ms\n",
      "Speed: 2.1ms preprocess, 89.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 1 bed, 102.6ms\n",
      "Speed: 1.3ms preprocess, 102.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bed, 1 refrigerator, 66.2ms\n",
      "Speed: 1.3ms preprocess, 66.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 2 beds, 56.8ms\n",
      "Speed: 1.1ms preprocess, 56.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 chairs, 1 bed, 74.2ms\n",
      "Speed: 1.1ms preprocess, 74.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 chairs, 1 bed, 62.5ms\n",
      "Speed: 1.1ms preprocess, 62.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 chairs, 1 bed, 56.9ms\n",
      "Speed: 1.3ms preprocess, 56.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 chairs, 2 beds, 58.1ms\n",
      "Speed: 1.1ms preprocess, 58.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 2 beds, 59.0ms\n",
      "Speed: 1.1ms preprocess, 59.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 chairs, 3 beds, 66.1ms\n",
      "Speed: 1.1ms preprocess, 66.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 chairs, 3 beds, 1 refrigerator, 60.8ms\n",
      "Speed: 1.4ms preprocess, 60.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 chairs, 1 bed, 53.8ms\n",
      "Speed: 1.1ms preprocess, 53.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 chairs, 2 beds, 54.1ms\n",
      "Speed: 1.2ms preprocess, 54.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 2 beds, 59.4ms\n",
      "Speed: 1.1ms preprocess, 59.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 chairs, 2 beds, 1 refrigerator, 65.5ms\n",
      "Speed: 1.1ms preprocess, 65.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 chairs, 2 beds, 61.5ms\n",
      "Speed: 1.2ms preprocess, 61.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 chairs, 2 beds, 1 refrigerator, 63.3ms\n",
      "Speed: 1.2ms preprocess, 63.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 2 beds, 61.9ms\n",
      "Speed: 1.0ms preprocess, 61.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 beds, 1 refrigerator, 62.0ms\n",
      "Speed: 1.2ms preprocess, 62.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 beds, 1 refrigerator, 62.5ms\n",
      "Speed: 1.1ms preprocess, 62.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 2 beds, 1 refrigerator, 60.7ms\n",
      "Speed: 1.3ms preprocess, 60.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 3 beds, 1 refrigerator, 61.5ms\n",
      "Speed: 1.3ms preprocess, 61.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 2 beds, 59.2ms\n",
      "Speed: 1.2ms preprocess, 59.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 3 beds, 1 refrigerator, 60.8ms\n",
      "Speed: 1.2ms preprocess, 60.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 2 beds, 1 refrigerator, 68.5ms\n",
      "Speed: 2.2ms preprocess, 68.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 2 beds, 1 refrigerator, 68.9ms\n",
      "Speed: 1.2ms preprocess, 68.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 beds, 1 refrigerator, 62.2ms\n",
      "Speed: 1.3ms preprocess, 62.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 chairs, 2 beds, 1 refrigerator, 52.9ms\n",
      "Speed: 1.0ms preprocess, 52.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 chairs, 1 bed, 1 refrigerator, 57.7ms\n",
      "Speed: 1.2ms preprocess, 57.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 chairs, 2 beds, 67.4ms\n",
      "Speed: 1.4ms preprocess, 67.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 chairs, 3 beds, 1 refrigerator, 62.2ms\n",
      "Speed: 1.3ms preprocess, 62.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 2 beds, 1 refrigerator, 66.9ms\n",
      "Speed: 1.2ms preprocess, 66.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 chairs, 3 beds, 1 refrigerator, 51.8ms\n",
      "Speed: 1.0ms preprocess, 51.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 beds, 59.3ms\n",
      "Speed: 1.3ms preprocess, 59.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 chairs, 2 beds, 1 refrigerator, 60.1ms\n",
      "Speed: 1.3ms preprocess, 60.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 chairs, 3 beds, 1 refrigerator, 63.9ms\n",
      "Speed: 1.3ms preprocess, 63.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 chairs, 3 beds, 1 refrigerator, 52.3ms\n",
      "Speed: 1.3ms preprocess, 52.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 chairs, 3 beds, 64.3ms\n",
      "Speed: 1.2ms preprocess, 64.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 chairs, 3 beds, 1 refrigerator, 67.8ms\n",
      "Speed: 1.1ms preprocess, 67.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 chairs, 3 beds, 65.7ms\n",
      "Speed: 1.4ms preprocess, 65.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 chairs, 3 beds, 63.3ms\n",
      "Speed: 1.4ms preprocess, 63.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 chairs, 3 beds, 60.4ms\n",
      "Speed: 1.0ms preprocess, 60.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 chairs, 3 beds, 52.2ms\n",
      "Speed: 1.1ms preprocess, 52.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 2 beds, 62.2ms\n",
      "Speed: 1.3ms preprocess, 62.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 3 beds, 65.7ms\n",
      "Speed: 1.3ms preprocess, 65.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 chairs, 3 beds, 53.3ms\n",
      "Speed: 1.1ms preprocess, 53.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 chairs, 3 beds, 1 refrigerator, 57.8ms\n",
      "Speed: 1.3ms preprocess, 57.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO  # Import YOLO model from Ultralytics\n",
    "import supervision as sv  # Import the supervision library for annotations\n",
    "\n",
    "class ObjectDetectionWithWebcam:\n",
    "    \"\"\"\n",
    "    This class performs real-time object detection using a webcam and YOLO model.\n",
    "\n",
    "    Attributes:\n",
    "        model (YOLO): YOLO object detection model.\n",
    "        webcam (cv2.VideoCapture): Webcam object for capturing frames.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model_weights: str = 'yolov8s.pt'):\n",
    "        \"\"\"\n",
    "        Initializes the ObjectDetectionWithWebcam class.\n",
    "\n",
    "        Args:\n",
    "            model_weights (str): Path to the YOLO model weights file (default is 'yolov8s.pt').\n",
    "        \"\"\"\n",
    "        self.model = YOLO(model_weights)\n",
    "        self.webcam = cv2.VideoCapture(0)\n",
    "\n",
    "        if not self.webcam.isOpened():\n",
    "            raise RuntimeError(\"Cannot open webcam\")\n",
    "\n",
    "    def __del__(self):\n",
    "        \"\"\"\n",
    "        Cleans up resources by releasing the webcam.\n",
    "        \"\"\"\n",
    "        self.webcam.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    def detect_objects(self):\n",
    "        \"\"\"\n",
    "        Performs real-time object detection using the webcam and displays the annotated frames.\n",
    "        \"\"\"\n",
    "        while True:\n",
    "            # Read frame from webcam\n",
    "            ret, frame = self.webcam.read()\n",
    "\n",
    "            if not ret:\n",
    "                print(\"Can't receive frame (stream end?), Exiting ...\")\n",
    "                break\n",
    "            \n",
    "            # Perform object detection on the frame using the YOLO model\n",
    "            results = self.model(frame)[0]\n",
    "\n",
    "            # Convert YOLO detections to Supervision Detections format\n",
    "            detections = sv.Detections.from_ultralytics(results)\n",
    "\n",
    "            # Create a bounding box annotator with specified thickness\n",
    "            bounding_box_annotator = sv.BoundingBoxAnnotator(\n",
    "                thickness=4\n",
    "            )\n",
    "\n",
    "            # Create a label annotator\n",
    "            label_annotator = sv.LabelAnnotator()\n",
    "\n",
    "            # Filter out detections with class_id not equal to 0 (background class)\n",
    "            detections = detections[detections.class_id != 0]\n",
    "\n",
    "            # Get labels for each detected object\n",
    "            labels = [\n",
    "                self.model.model.names[class_id]\n",
    "                for class_id\n",
    "                in detections.class_id\n",
    "            ]\n",
    "\n",
    "            # Annotate the frame with bounding boxes\n",
    "            annotated_image = bounding_box_annotator.annotate(\n",
    "                scene=frame, detections=detections)\n",
    "\n",
    "            # Annotate the frame with labels\n",
    "            annotated_image = label_annotator.annotate(\n",
    "                scene=annotated_image, detections=detections, labels=labels)\n",
    "\n",
    "            # Display the annotated frame\n",
    "            cv2.imshow(\"Object Detection\", annotated_image)\n",
    "\n",
    "            # Exit loop if 'q' key is pressed\n",
    "            if cv2.waitKey(1) == ord(\"q\"):\n",
    "                break\n",
    "\n",
    "# Usage example:\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize ObjectDetectionWithWebcam class\n",
    "    detector = ObjectDetectionWithWebcam()\n",
    "\n",
    "    # Perform real-time object detection\n",
    "    detector.detect_objects()\n",
    "    detector.__del__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv-tutorial-cap-aU5aeIk7-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
