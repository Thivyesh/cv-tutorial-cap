{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real-time Object Detection with YOLO and OpenCV\n",
    "\n",
    "## Overview:\n",
    "\n",
    "This script demonstrates real-time object detection using the You Only Look Once (YOLO) model and OpenCV. YOLO is a popular deep learning-based object detection algorithm that is known for its speed and accuracy. OpenCV is a powerful library used for computer vision tasks, including image processing and object detection.\n",
    "\n",
    "## Concepts:\n",
    "\n",
    "### YOLO (You Only Look Once):\n",
    "   - YOLO is a real-time object detection algorithm that detects objects in images or video frames.\n",
    "   - It divides the input image into a grid and predicts bounding boxes and class probabilities for each grid cell simultaneously.\n",
    "   - YOLO can detect multiple objects in a single pass through the neural network, making it extremely fast.\n",
    "\n",
    "### OpenCV:\n",
    "   - OpenCV (Open Source Computer Vision Library) is an open-source computer vision and machine learning software library.\n",
    "   - It provides a wide range of tools and algorithms for image and video processing tasks.\n",
    "   - OpenCV is widely used for tasks such as object detection, facial recognition, and image segmentation.\n",
    "\n",
    "## Code Explanation:\n",
    "\n",
    "### Importing Libraries:\n",
    "  - The script imports necessary libraries including `cv2` for OpenCV, `YOLO` from `ultralytics` for object detection, and `supervision` for annotations.\n",
    "\n",
    "### Initializing YOLO Model:\n",
    "  - The YOLO model is initialized using pre-trained weights (`yolov8s.pt`). These weights are obtained from training on a large dataset and are used to perform object detection.\n",
    "\n",
    "### Initializing Webcam Capture:\n",
    "  - The script initializes webcam capture using OpenCV's `VideoCapture` class. If the webcam cannot be opened, an error message is printed and the script exits.\n",
    "\n",
    "### Real-time Object Detection Loop:\n",
    "  - The script enters a while loop to continuously capture frames from the webcam and perform object detection on each frame.\n",
    "  - Each frame captured from the webcam is passed through the YOLO model to detect objects.\n",
    "  - Detected objects are annotated with bounding boxes and labels using the `supervision` library.\n",
    "  - Annotated frames are displayed in real-time using OpenCV's `imshow` function.\n",
    "  - The loop continues until the user presses the 'q' key, at which point the webcam is released and OpenCV windows are closed.\n",
    "\n",
    "## Conclusion:\n",
    "\n",
    "This script provides a simple yet powerful demonstration of real-time object detection using YOLO and OpenCV. By leveraging pre-trained models and libraries, developers can quickly build applications for various computer vision tasks such as surveillance, object tracking, and augmented reality.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Object Detection:\n",
    "   - Object detection is a computer vision task that involves detecting and locating objects within an image or video frame.\n",
    "   - It differs from image classification, which identifies the main object in an entire image, by providing the precise location of each object along with its class label.\n",
    "   - Object detection algorithms typically use machine learning techniques, such as deep neural networks, to perform this task.\n",
    "\n",
    "### Real-time Object Detection vs Batch Object Detection:\n",
    "   - Real-time object detection refers to the ability to perform object detection on live video streams in real-time, usually at frame rates of at least 30 frames per second (FPS).\n",
    "   - Batch object detection, on the other hand, involves processing a batch of images or video frames offline, without the constraint of real-time processing.\n",
    "   - Real-time object detection is often used in applications such as video surveillance, autonomous driving, and augmented reality, where timely detection of objects is critical.\n",
    "\n",
    "### YOLOv8 Architecture:\n",
    "   - YOLOv8 (You Only Look Once version 8) is an improvement over previous versions of the YOLO algorithm, known for its efficiency and accuracy in object detection tasks.\n",
    "   - YOLOv8 is based on a deep convolutional neural network architecture that divides the input image into a grid of cells and predicts bounding boxes and class probabilities for each cell simultaneously.\n",
    "   - It uses a single neural network to predict multiple bounding boxes and class probabilities for each object in the image, making it extremely fast and efficient.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO  # Import YOLO model from Ultralytics\n",
    "import supervision as sv  # Import the supervision library for annotations\n",
    "\n",
    "class ObjectDetectionWithWebcam:\n",
    "    \"\"\"\n",
    "    This class performs real-time object detection using a webcam and YOLO model.\n",
    "\n",
    "    Attributes:\n",
    "        model (YOLO): YOLO object detection model.\n",
    "        webcam (cv2.VideoCapture): Webcam object for capturing frames.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model_weights: str = 'yolov8s.pt'):\n",
    "        \"\"\"\n",
    "        Initializes the ObjectDetectionWithWebcam class.\n",
    "\n",
    "        Args:\n",
    "            model_weights (str): Path to the YOLO model weights file (default is 'yolov8s.pt').\n",
    "        \"\"\"\n",
    "        self.model = YOLO(model_weights)\n",
    "        self.webcam = cv2.VideoCapture(0)\n",
    "\n",
    "        if not self.webcam.isOpened():\n",
    "            raise RuntimeError(\"Cannot open webcam\")\n",
    "\n",
    "    def __del__(self):\n",
    "        \"\"\"\n",
    "        Cleans up resources by releasing the webcam.\n",
    "        \"\"\"\n",
    "        self.webcam.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    def detect_objects(self):\n",
    "        \"\"\"\n",
    "        Performs real-time object detection using the webcam and displays the annotated frames.\n",
    "        \"\"\"\n",
    "        while True:\n",
    "            # Read frame from webcam\n",
    "            ret, frame = self.webcam.read()\n",
    "\n",
    "            if not ret:\n",
    "                print(\"Can't receive frame (stream end?), Exiting ...\")\n",
    "                break\n",
    "            \n",
    "            # Perform object detection on the frame using the YOLO model\n",
    "            results = self.model(frame)[0]\n",
    "\n",
    "            # Convert YOLO detections to Supervision Detections format\n",
    "            detections = sv.Detections.from_ultralytics(results)\n",
    "\n",
    "            # Create a bounding box annotator with specified thickness\n",
    "            bounding_box_annotator = sv.BoundingBoxAnnotator(\n",
    "                thickness=4\n",
    "            )\n",
    "\n",
    "            # Create a label annotator\n",
    "            label_annotator = sv.LabelAnnotator()\n",
    "\n",
    "            # Filter out detections with class_id not equal to 0 (background class)\n",
    "            detections = detections[detections.class_id != 0]\n",
    "\n",
    "            # Get labels for each detected object\n",
    "            labels = [\n",
    "                self.model.model.names[class_id]\n",
    "                for class_id\n",
    "                in detections.class_id\n",
    "            ]\n",
    "\n",
    "            # Annotate the frame with bounding boxes\n",
    "            annotated_image = bounding_box_annotator.annotate(\n",
    "                scene=frame, detections=detections)\n",
    "\n",
    "            # Annotate the frame with labels\n",
    "            annotated_image = label_annotator.annotate(\n",
    "                scene=annotated_image, detections=detections, labels=labels)\n",
    "\n",
    "            # Display the annotated frame\n",
    "            cv2.imshow(\"Object Detection\", annotated_image)\n",
    "\n",
    "            # Exit loop if 'q' key is pressed\n",
    "            if cv2.waitKey(1) == ord(\"q\"):\n",
    "                break\n",
    "\n",
    "# Usage example:\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize ObjectDetectionWithWebcam class\n",
    "    detector = ObjectDetectionWithWebcam()\n",
    "\n",
    "    # Perform real-time object detection\n",
    "    detector.detect_objects()\n",
    "    detector.__del__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DETR (DEtection TRansformers) Model:\n",
    "   - DETR is a state-of-the-art object detection model that utilizes transformer architecture, originally proposed by Facebook AI.\n",
    "   - Unlike traditional object detection models that rely on anchor boxes and proposal generation, DETR directly predicts object bounding boxes and class labels in a single pass using transformer-based encoder-decoder architecture.\n",
    "   - It has been shown to achieve competitive performance on object detection benchmarks with fewer heuristics and hyperparameters.\n",
    "\n",
    "## YOLOv8 vs. DETR:\n",
    "\n",
    "### YOLOv8:\n",
    "   - YOLOv8 is well-suited for real-time applications where speed and efficiency are crucial, such as video surveillance and object tracking.\n",
    "   - It provides a simpler and faster approach to object detection compared to DETR, making it easier to deploy in resource-constrained environments.\n",
    "\n",
    "### DETR:\n",
    "   - DETR offers a novel approach to object detection using transformer architecture, which allows for end-to-end training and inference.\n",
    "   - It is suitable for applications where precise localization and accurate detection of objects are important, such as autonomous driving and medical imaging.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from transformers import pipeline\n",
    "from PIL import ImageDraw, Image\n",
    "import numpy as np\n",
    "import supervision as sv\n",
    "\n",
    "class ObjectDetectionWithWebcam:\n",
    "    \"\"\"\n",
    "    This class performs real-time object detection using a webcam and DETR model.\n",
    "\n",
    "    Attributes:\n",
    "        detector: DETR object detection pipeline.\n",
    "        webcam (cv2.VideoCapture): Webcam object for capturing frames.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, checkpoint: str = \"facebook/detr-resnet-50\"):\n",
    "        \"\"\"\n",
    "        Initializes the ObjectDetectionWithWebcam class.\n",
    "\n",
    "        Args:\n",
    "            checkpoint (str): Name or path of the DETR checkpoint (default is \"facebook/detr-resnet-50\").\n",
    "        \"\"\"\n",
    "        self.detector = pipeline(model=checkpoint, task=\"object-detection\")\n",
    "        self.webcam = cv2.VideoCapture(0)\n",
    "\n",
    "        if not self.webcam.isOpened():\n",
    "            raise RuntimeError(\"Cannot open webcam\")\n",
    "\n",
    "    def __del__(self):\n",
    "        \"\"\"\n",
    "        Cleans up resources by releasing the webcam.\n",
    "        \"\"\"\n",
    "        self.webcam.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    def detect_objects(self):\n",
    "        \"\"\"\n",
    "        Performs real-time object detection using the webcam and displays the annotated frames.\n",
    "        \"\"\"\n",
    "        while True:\n",
    "            # Read frame from webcam\n",
    "            ret, frame = self.webcam.read()\n",
    "\n",
    "            if not ret:\n",
    "                print(\"Can't receive frame (stream end?), Exiting ...\")\n",
    "                break\n",
    "\n",
    "            # Convert frame to RGB format\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frame = Image.fromarray(frame)\n",
    "\n",
    "            # Predict objects in the frame\n",
    "            predictions = self.detector(frame, candidate_labels=[\"human face\"])\n",
    "\n",
    "            # Annotate the frame with predicted bounding boxes and labels\n",
    "            draw = ImageDraw.Draw(frame)\n",
    "            for prediction in predictions:\n",
    "                box = prediction[\"box\"]\n",
    "                label = prediction[\"label\"]\n",
    "                score = prediction[\"score\"]\n",
    "\n",
    "                xmin, ymin, xmax, ymax = box.values()\n",
    "                draw.rectangle((xmin, ymin, xmax, ymax), outline=\"red\", width=1)\n",
    "                draw.text((xmin, ymin), f\"{label}: {round(score, 2)}\", fill=\"white\")\n",
    "\n",
    "            # Convert annotated frame back to OpenCV format\n",
    "            frame = np.array(frame)\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            # Display the annotated frame\n",
    "            cv2.imshow(\"Object Detection\", frame)\n",
    "\n",
    "            # Exit loop if 'q' key is pressed\n",
    "            if cv2.waitKey(1) == ord(\"q\"):\n",
    "                break\n",
    "\n",
    "# Usage example:\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize ObjectDetectionWithWebcam class\n",
    "    detector = ObjectDetectionWithWebcam()\n",
    "\n",
    "    # Perform real-time object detection\n",
    "    detector.detect_objects()\n",
    "    detector.__del__()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv-tutorial-cap-aU5aeIk7-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
